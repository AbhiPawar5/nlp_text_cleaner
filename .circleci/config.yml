version: 2.1
jobs:
  build_test:
    docker:
      - image: continuumio/miniconda3
    working_directory: ~/code
    steps:
    # Step 1: checkout source code to working directory
      - checkout  
    # Step 2: create virtual env and install dependencies
      - run:
          name: install dependencies
          command: |
            conda env create -f environment.yml
            source activate nlp_text_cleaner
    # Step 3: run tests
      - run:
          name: run tests and linting
          command: |
            source activate nlp_text_cleaner
            pylint nlp_text_cleaner
            pytest -vv
            pytest --cov-report html:tests/cov_html --cov=nlp_text_cleaner tests/
      - store_artifacts:
          path: tests/cov_html
  pypi_publish:
    docker:
      - image: continuumio/miniconda3
    working_directory: ~/code
    steps:
    # Step 1: checkout source code to working directory
      - checkout
    # Step 2: create virtual env and install dependencies	  
      - run:
          name: run pypi publish
          command: |  # create whl, install twine and publish to PyPI
            conda env create -f environment.yml
            source activate nlp_text_cleaner
            python -m build
            python -m twine check dist/* 
            python -m twine upload dist/*
workflows:
  build_test_publish:
    jobs:
      - build_test
      - pypi_publish:
          requires:
            - build_test
          filters:
            branches:
              only:
                - master